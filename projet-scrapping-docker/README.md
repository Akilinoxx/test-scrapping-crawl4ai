# ğŸ•·ï¸ Web Scraping & AI Chatbot Pipeline

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Un pipeline complet de scraping web, vectorisation et chatbot IA utilisant **Crawl4AI**, **Mistral AI** et **Pinecone** pour crÃ©er un systÃ¨me de recherche sÃ©mantique intelligent.

## ğŸš€ FonctionnalitÃ©s

### ğŸ“Š Web Scraping
- **Extraction automatique** des sitemaps depuis robots.txt
- **Scraping parallÃ©lisÃ©** avec gestion des dÃ©lais et retry
- **Support multi-sites** avec configuration flexible
- **Stockage organisÃ©** en fichiers Markdown par site

### ğŸ§  Intelligence Artificielle
- **Vectorisation** du contenu avec Mistral AI embeddings
- **Base vectorielle** Pinecone pour recherche sÃ©mantique
- **Chatbot interactif** avec historique et citations
- **Recherche contextuelle** dans tout le contenu scrapÃ©

### ğŸ³ Containerisation
- **Docker Compose** pour orchestration complÃ¨te
- **Services sÃ©parÃ©s** : scraper, vectorizer, chatbot
- **Volumes persistants** pour donnÃ©es et conversations
- **Scripts multi-plateformes** (Windows/Linux/Mac)

## ğŸ› ï¸ Technologies

- **Python 3.10+** - Langage principal
- **Crawl4AI** - Web scraping intelligent
- **Mistral AI** - Embeddings et gÃ©nÃ©ration de texte
- **Pinecone** - Base de donnÃ©es vectorielle
- **Docker** - Containerisation
- **Playwright** - Automation navigateur

## ğŸ“¦ Installation Rapide

### PrÃ©requis
- [Docker Desktop](https://www.docker.com/products/docker-desktop/)
- [Python 3.10+](https://www.python.org/downloads/) (pour usage local)

### ğŸš€ DÃ©marrage avec Docker

```bash
# Cloner le projet
git clone https://github.com/votre-username/web-scraping-ai-chatbot.git
cd web-scraping-ai-chatbot

# Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env avec vos clÃ©s API

# Construire et lancer tous les services
./run-docker.sh all        # Linux/Mac
.\run-docker.bat all       # Windows
```

### ğŸ’» Installation Locale

```bash
# Installer les dÃ©pendances
pip install -r requirements_vector.txt

# Installer Playwright
python -m playwright install

# Lancer le chatbot
python chatbot.py
```

## ğŸ¯ Utilisation

### 1. Configuration des APIs

CrÃ©ez un fichier `.env` avec vos clÃ©s :

```env
MISTRAL_API_KEY=votre_cle_mistral
PINECONE_API_KEY=votre_cle_pinecone
PINECONE_HOST=votre_host_pinecone
```

### 2. Scraping de Sites

```bash
# Scraper des sites spÃ©cifiques
python app.py --sites https://example.com --output-dir scraped_data

# Ou utiliser Docker
docker-compose -f docker-compose.complete.yml up scraper
```

### 3. Vectorisation

```bash
# Vectoriser le contenu scrapÃ©
python vector_store.py

# Ou avec Docker
docker-compose -f docker-compose.complete.yml up vectorizer
```

### 4. Chatbot Interactif

```bash
# Lancer le chatbot
python chatbot.py

# Ou avec Docker
docker-compose -f docker-compose.chatbot.yml up
```

## ğŸ³ Commandes Docker

```bash
# Construire toutes les images
./run-docker.sh build

# Lancer le pipeline complet
./run-docker.sh all

# Lancer uniquement le chatbot
./run-docker.sh chatbot

# Nettoyer les conteneurs
./run-docker.sh clean
```

## ğŸ“ Structure du Projet

```
â”œâ”€â”€ ğŸ“ src/                     # Code source principal
â”‚   â”œâ”€â”€ app.py                  # Application de scraping
â”‚   â”œâ”€â”€ chatbot.py             # Chatbot interactif
â”‚   â”œâ”€â”€ vector_store.py        # Vectorisation
â”‚   â””â”€â”€ content_scraper.py     # Scraper de contenu
â”œâ”€â”€ ğŸ“ docker/                 # Configuration Docker
â”‚   â”œâ”€â”€ Dockerfile             # Image scraper
â”‚   â”œâ”€â”€ Dockerfile.chatbot     # Image chatbot
â”‚   â””â”€â”€ Dockerfile.vector      # Image vectorizer
â”œâ”€â”€ ğŸ“ scripts/                # Scripts utilitaires
â”‚   â”œâ”€â”€ run-docker.sh         # Script Linux/Mac
â”‚   â””â”€â”€ run-docker.bat        # Script Windows
â”œâ”€â”€ ğŸ“ data/                   # DonnÃ©es (gitignore)
â”‚   â”œâ”€â”€ scraped_content_md/   # Contenu scrapÃ©
â”‚   â”œâ”€â”€ scraped_links/        # URLs extraites
â”‚   â””â”€â”€ conversations/        # Historique chatbot
â”œâ”€â”€ docker-compose.*.yml       # Configurations Docker
â”œâ”€â”€ requirements*.txt          # DÃ©pendances Python
â””â”€â”€ .env.example              # Template configuration
```

## ğŸ”§ Configuration AvancÃ©e

### Variables d'Environnement

| Variable | Description | DÃ©faut |
|----------|-------------|---------|
| `MISTRAL_API_KEY` | ClÃ© API Mistral AI | Requis |
| `PINECONE_API_KEY` | ClÃ© API Pinecone | Requis |
| `PINECONE_HOST` | Host Pinecone | Requis |
| `SCRAPER_DELAY` | DÃ©lai entre requÃªtes (s) | 1 |
| `MAX_WORKERS` | Threads parallÃ¨les | 5 |

### Personnalisation du Scraping

Modifiez `sites_example.txt` pour ajouter vos sites :
```
https://example1.com
https://example2.com
https://example3.com
```

## ğŸ“Š Monitoring et Logs

```bash
# Voir les logs en temps rÃ©el
docker-compose logs -f chatbot

# Statistiques des conteneurs
docker stats

# VÃ©rifier l'Ã©tat des services
docker-compose ps
```

## ğŸ¤ Contribution

1. **Fork** le projet
2. **CrÃ©er** une branche feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** vos changements (`git commit -m 'Add AmazingFeature'`)
4. **Push** vers la branche (`git push origin feature/AmazingFeature`)
5. **Ouvrir** une Pull Request

## ğŸ“ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ†˜ Support

- ğŸ“– [Documentation complÃ¨te](./docs/)
- ğŸ› [Signaler un bug](https://github.com/votre-username/web-scraping-ai-chatbot/issues)
- ğŸ’¬ [Discussions](https://github.com/votre-username/web-scraping-ai-chatbot/discussions)

## ğŸ™ Remerciements

- [Crawl4AI](https://github.com/unclecode/crawl4ai) - Framework de scraping
- [Mistral AI](https://mistral.ai/) - ModÃ¨les d'IA
- [Pinecone](https://www.pinecone.io/) - Base vectorielle

---

â­ **N'oubliez pas de donner une Ã©toile si ce projet vous aide !**
